{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multi-Class Classification with Perceptron\n",
    "\n",
    "Lab Assignment from [AI for Beginners Curriculum](https://github.com/microsoft/ai-for-beginners)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "np.random.seed(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the following perceptron training code from the lecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def train(positive_examples, negative_examples, num_iterations = 100, learning_rate=1):\n",
    "    num_dims = positive_examples.shape[1]\n",
    "    weights = np.zeros(num_dims) # initialize weights\n",
    "    \n",
    "#    pos_count = positive_examples.shape[0]\n",
    "#    neg_count = negative_examples.shape[0]\n",
    "    \n",
    "#    report_frequency = 10\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        pos = random.choice(positive_examples)\n",
    "        neg = random.choice(negative_examples)\n",
    "        \n",
    "        z = np.dot(pos, weights)   \n",
    "        if z < 0:\n",
    "            weights = weights + learning_rate*pos.reshape(weights.shape)\n",
    "\n",
    "        z  = np.dot(neg, weights)\n",
    "        if z >= 0:\n",
    "            weights = weights - learning_rate*neg.reshape(weights.shape)\n",
    "            \n",
    "        #if i % report_frequency == 0:             \n",
    "#        if i == num_iterations-1:\n",
    "#            pos_out = np.dot(positive_examples, weights)\n",
    "#            neg_out = np.dot(negative_examples, weights)        \n",
    "#            pos_correct = (pos_out >= 0).sum() / float(pos_count)\n",
    "#            neg_correct = (neg_out < 0).sum() / float(neg_count)\n",
    "#            print(\"pos correct={}, neg correct={}\".format(pos_correct,neg_correct))\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_norm(positive_examples, negative_examples, num_iterations = 100, learning_rate=1):\n",
    "    #previously normalizes the examples by dividing by the norm of the array\n",
    "    \n",
    "    num_dims = positive_examples.shape[1]\n",
    "    weights = np.zeros(num_dims) # initialize weights\n",
    "    \n",
    "    pos_norms = np.array([np.linalg.norm(positive_examples,axis=1)])\n",
    "    pos_norms = pos_norms.transpose()\n",
    "    norm_positive_examples = np.divide(positive_examples,pos_norms)\n",
    "    neg_norms = np.array([np.linalg.norm(negative_examples,axis=1)])\n",
    "    neg_norms = neg_norms.transpose()\n",
    "    norm_negative_examples = np.divide(negative_examples,neg_norms)\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        pos = random.choice(norm_positive_examples)\n",
    "        neg = random.choice(norm_negative_examples)\n",
    "\n",
    "        z = np.dot(pos, weights)   \n",
    "        if z < 0:\n",
    "            weights = weights + learning_rate*pos.reshape(weights.shape)\n",
    "\n",
    "        z  = np.dot(neg, weights)\n",
    "        if z >= 0:\n",
    "            weights = weights - learning_rate*neg.reshape(weights.shape)\n",
    "            \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(weights, test_x, test_labels):\n",
    "    res = np.dot(np.c_[test_x,np.ones(len(test_x))],weights)\n",
    "    return (res.reshape(test_labels.shape)*test_labels>=0).sum()/float(len(test_labels))\n",
    "\n",
    "#accuracy(weights, test_x, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reading the Dataset\n",
    "\n",
    "This code download the dataset from the repository on the internet. You can also manually copy the dataset from `/data` directory of AI Curriculum repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#File https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/data/mnist.pkl.gz was donwloaded manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "with gzip.open('mnist.pkl.gz', 'rb') as mnist_pickle:\n",
    "    #MNIST = pickle.load(mnist_pickle,encoding='latin1')\n",
    "    training_data, validation_data, test_data = pickle.load(mnist_pickle,encoding='latin1')\n",
    "#MNIST = pd.read_pickle('mnist.pkl.gz',compression='gzip')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We add a 1 at the end of every matrix to add a bias term to our model\n",
    "train_with_bias=np.concatenate((training_data[0],np.ones((50000,1))),axis=1)\n",
    "training_data_bias = (train_with_bias,training_data[1])\n",
    "test_with_bias=np.concatenate((test_data[0],np.ones((10000,1))),axis=1)\n",
    "test_data_bias = (test_with_bias,test_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#..._data[0] contains an array of arrays of the images of the digits as a size 784 array\n",
    "#..._data[0][N] is the N+1th matrix\n",
    "#..._data[1] contains a list with the label of every digit the images represent\n",
    "#training data contains 50000 samples and validation and test data 10000 each. \n",
    "\n",
    "#the ..._data[0][N] are the features and the ..._data[1] are the labels\n",
    "\n",
    "#the training algorithm takes as input positive examples, negative examples and the number of iterations\n",
    "#the perceptron we are using is a multilinear model, using a hyperplane to separate 2 outcomes and using gradient descent to\n",
    "#update its weights.\n",
    "#for the training process of the weights it chooses a random positive example and a random negative example and uses them to \n",
    "#update the weights only if the dot product misclassifies the example.\n",
    "#to simplify the addition of a bias term in the model we add another feature that always equals 1. This results in the last \n",
    "#dimension of theh weight vector being the bias. \n",
    "#positive and negative examples are just a way to differentiate the 2 possible outcomes of the binary classifier and have no \n",
    "#relation to whether or not the model classified the example correctly. \n",
    "#to build the digit classifier we will build 10 binary classifiers, each one classifying a certain digit and not that digit. \n",
    "#in the case of multiple classifiers deciding it is a certain digit, the bigger dot product should be better because the\n",
    "#error grows as the dot product approaches 0 and decreases as the dot product increases. \n",
    "\n",
    "#build a one vs all first and a one vs one maybe later "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_digit(array):\n",
    "    matrix = array.reshape(28,28)\n",
    "    fig, ax = plt.subplots(1,1,figsize=(5,5)) #12\n",
    "    im=ax.matshow(matrix,aspect='auto')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label is: 4\n"
     ]
    }
   ],
   "source": [
    "#Check the imported data\n",
    "arrayid = 127\n",
    "\n",
    "matrix = training_data[0][arrayid].reshape(28,28)\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,5)) #12\n",
    "im=ax.matshow(matrix,aspect='auto')\n",
    "plt.show()\n",
    "print(\"The label is:\",training_data[1][arrayid])\n",
    "\n",
    "\n",
    "#Check the classifier\n",
    "#                     0 correct 1 incorrect\n",
    "#                               |\n",
    "#matrix = dataset_classifier(5)[0][245].reshape(28,28)\n",
    "#fig, ax = plt.subplots(1,1,figsize=(5,5)) #12\n",
    "#im=ax.matshow(matrix,aspect='auto')\n",
    "#plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Create the datasets for the one vs all classifier and one vs one classifier. The digit/s we want to differentiate is the input. \n",
    "def dataset_classifier(digits,training_data_):\n",
    "    #takes a digit as input and outputs the training data, classified based on the digit provided. If two digits are provided \n",
    "    #as a list it classifies the training data based on the 2. \n",
    "    \n",
    "    if isinstance(digits, int):\n",
    "    #one vs all classifier\n",
    "        positive_label = digits\n",
    "        #negative label is unnecessary\n",
    "        \n",
    "        positive_indices = [i for i, j in enumerate(training_data_[1]) \n",
    "                          if j == positive_label]\n",
    "        negative_indices = [i for i, j in enumerate(training_data_[1]) \n",
    "                          if j != positive_label]\n",
    "        \n",
    "        positive_dataset = training_data_[0][positive_indices]\n",
    "        negative_dataset = training_data_[0][negative_indices]\n",
    "        \n",
    "        return positive_dataset,negative_dataset\n",
    "    \n",
    "    elif (isinstance(digits, list) and len(digits)==2):\n",
    "    #one vs one classifier\n",
    "        positive_label = digits[0]\n",
    "        negative_label = digits[1]\n",
    "        \n",
    "        positive_indices = [i for i, j in enumerate(training_data_[1]) \n",
    "                          if j == positive_label]\n",
    "        negative_indices = [i for i, j in enumerate(training_data_[1]) \n",
    "                          if j == negative_label]\n",
    "        \n",
    "        positive_dataset = training_data_[0][positive_indices]\n",
    "        negative_dataset = training_data_[0][negative_indices]\n",
    "        \n",
    "        return positive_dataset,negative_dataset\n",
    "        \n",
    "    else:\n",
    "        print('Wrong digits input for the dataset classifier')\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_training(training_data_):\n",
    "#creates 10 one vs all classifiers, trains them and stores the weights. The weights are stored as a list of arrays where the \n",
    "#digit corresponds with the index of the list.\n",
    "    weights = []\n",
    "    for digit in range(0,10):\n",
    "        positive_dataset,negative_dataset = dataset_classifier(digit,training_data_)\n",
    "        weights.append(train(positive_dataset, negative_dataset, num_iterations = 100, learning_rate=1))\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_accuracy(weights,test_data_):\n",
    "#takes a digit from the test data and uses the weights to determine the likelihood of each digit. \n",
    "#The largest dot product is the most likely\n",
    "#returns accuracy\n",
    "    true_digits = test_data_[1]\n",
    "    detected_digits = np.zeros(true_digits.shape[0])\n",
    "    for i,digit in enumerate(test_data_[0]):\n",
    "        dot_digit = []\n",
    "        #calculates the dot product for every digit and chooses the maximum as the correct digit\n",
    "        for n in range(0,10):\n",
    "            dot_digit.append(np.dot(weights[n],digit))\n",
    "        detected_digits[i] = dot_digit.index(max(dot_digit))\n",
    "    #Number of digits correcty predicted\n",
    "    corr_pred = true_digits[true_digits==detected_digits].shape[0]\n",
    "    #accuracy\n",
    "    acc = corr_pred/true_digits.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_accuracy_matrix(weights,test_data_):\n",
    "#takes a digit from the test data and uses the weights to determine the likelihood of each digit. \n",
    "#The largest dot product is the most likely\n",
    "#returns accuracy\n",
    "    true_digits = test_data_[1]\n",
    "    detected_digits = np.zeros(true_digits.shape[0])\n",
    "    weights_matrix = np.matrix(weights)\n",
    "    confusion_matrix = np.zeros((10,10))\n",
    "    #uses a matrix multiplication to obtain the dot product for every digit\n",
    "    for i,digit in enumerate(test_data_[0]):\n",
    "        detected_digits[i] = weights_matrix.dot(digit).argmax()\n",
    "    for tdigit,ddigit in zip(true_digits,detected_digits):\n",
    "        if ddigit == tdigit:\n",
    "            confusion_matrix[int(ddigit),int(ddigit)] += 1\n",
    "        else:\n",
    "            confusion_matrix[int(ddigit),int(tdigit)] += 1\n",
    "\n",
    "            \n",
    "    #Number of digits correcty predicted\n",
    "    corr_pred = true_digits[true_digits==detected_digits].shape[0]\n",
    "    #accuracy\n",
    "    acc = corr_pred/true_digits.shape[0]\n",
    "    return acc,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 36.48776626586914 seconds.\n",
      "The average accuracy over 10 trials is \n",
      " 0.6711499999999999 for data with no bias term \n",
      " 0.7054500000000001 for data with a bias term\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "acc_bias = []\n",
    "conf = []\n",
    "conf_bias = []\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "for n in range(10):\n",
    "    weights = perceptron_training(training_data)\n",
    "    acc.append(model_accuracy_matrix(weights,test_data)[0])\n",
    "    conf.append(model_accuracy_matrix(weights,test_data)[1])\n",
    "\n",
    "    weights = perceptron_training(training_data_bias)\n",
    "    acc_bias.append(model_accuracy_matrix(weights,test_data_bias)[0])\n",
    "    conf_bias.append(model_accuracy_matrix(weights,test_data_bias)[1])\n",
    "\n",
    "print('It took', time.time()-start, 'seconds.')\n",
    "print('The average accuracy over',n+1,'trials is \\n',sum(acc)/len(acc),'for data with no bias term \\n',\n",
    "      sum(acc_bias)/len(acc_bias),'for data with a bias term')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 most mislabeled pairs are:\n",
      "[7, 9] 2.053 %\n",
      "[9, 4] 1.561 %\n",
      "[5, 3] 1.483 %\n",
      "[8, 1] 1.471 %\n",
      "[9, 7] 1.149 %\n",
      "[5, 8] 1.086 %\n",
      "[8, 2] 1.026 %\n",
      "[2, 3] 1.025 %\n",
      "[8, 5] 0.92 %\n",
      "[2, 8] 0.883 %\n"
     ]
    }
   ],
   "source": [
    "sum_conf = sum(conf)\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,5)) #12\n",
    "im=ax.matshow(sum_conf,aspect='auto')\n",
    "plt.title('Average confusion matrix')\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('detected label')\n",
    "plt.show()\n",
    "max_conf = [0]\n",
    "conf_pairs = [0]\n",
    "N_max = 10\n",
    "N = sum_conf.sum()/100\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if i != j:\n",
    "            if sum_conf[i,j]/N > max_conf[-1]:\n",
    "                max_conf.append(sum_conf[i,j]/N)\n",
    "                conf_pairs.append([i,j])\n",
    "            elif sum_conf[i,j]/N > max_conf[0]:\n",
    "                for n,m in enumerate(max_conf[1:]): \n",
    "                    if sum_conf[i,j]/N < m:\n",
    "                        max_conf.insert(n+1,sum_conf[i,j]/N)\n",
    "                        conf_pairs.insert(n+1,[i,j])\n",
    "                        break\n",
    "            if len(max_conf) > N_max:\n",
    "                max_conf.pop(0)\n",
    "                conf_pairs.pop(0)\n",
    "\n",
    "print('The',N_max,'most mislabeled pairs are:')\n",
    "for pair,perc in zip(list(reversed(conf_pairs)),list(reversed(max_conf))):\n",
    "    print(pair,perc,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  2,  5],\n",
       "       [11,  5, 11]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(1 2 3) (1 0 1)             (4+1  2+0 4+1 )\n",
    "#(4 5 6) (0 1 0) + (1 0 1) = (10+1 5+0 10+1)\n",
    "#        (1 0 1)\n",
    "#bias is added to every row\n",
    "\n",
    "TV = np.array([[1,2,3],[4,5,6]])\n",
    "AB = np.array([[1,0,1],[0,1,0],[1,0,1]])\n",
    "#BIAS = 4*np.ones((1,3)) #(1,n_dim)\n",
    "BIAS = np.array([1,0,1])[np.newaxis]\n",
    "OU = np.matmul(TV,AB) + BIAS\n",
    "OU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TV.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n",
      "(784,)\n",
      "(784,)\n",
      "(784,)\n"
     ]
    }
   ],
   "source": [
    "for t in training_data[0][0:4]:\n",
    "    print(t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "livereveal": {
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
